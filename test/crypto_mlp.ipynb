{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def set_seed(seed=0):\n",
    "    seed = 42069  # set a random seed for reproducibility\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def init_weight():\n",
    "    # y0 dim: (1, 2)\n",
    "    w1 = np.array([[0.2, 0.3],\n",
    "                   [0.4, 0.2],\n",
    "                   [0.3, 0.4]], dtype='f')\n",
    "    # y1 dim: (1, 3)\n",
    "    w2 = np.array([[0.2, 0.3, 0.4],\n",
    "                   [0.4, 0.2, 0.3],\n",
    "                   [0.3, 0.4, 0.2]], dtype='f')\n",
    "    # y2 dim: (1, 3)\n",
    "    w3 = np.array([[0.2, 0.3, 0.4],\n",
    "                   [0.4, 0.2, 0.3]], dtype='f')\n",
    "    # y3 dim: (1, 2)\n",
    "    return w1, w2, w3\n",
    "\n",
    "\n",
    "class CMlp(nn.Module):\n",
    "\n",
    "    def __init__(self, encrypt=False):\n",
    "        super(CMlp, self).__init__()\n",
    "        w1, w2, w3 = init_weight()\n",
    "\n",
    "        self.fc1 = nn.Linear(2, 3, False)\n",
    "        self.fc1.weight.data = torch.from_numpy(w1)\n",
    "        self.fc2 = nn.Linear(3, 3, False)\n",
    "        self.fc2.weight.data = torch.from_numpy(w2)\n",
    "        self.fc3 = nn.Linear(3, 2, False)\n",
    "        self.fc3.weight.data = torch.from_numpy(w3)\n",
    "        if encrypt:\n",
    "            rng = default_rng(0)\n",
    "            self.r1 = rng.standard_normal((3, 1), dtype='f')\n",
    "            self.r2 = rng.standard_normal((3, 1), dtype='f')\n",
    "            self.r3 = rng.standard_normal((2, 1), dtype='f')\n",
    "            self.fc1.weight.data = torch.from_numpy(w1 * self.r1)\n",
    "            self.fc2.weight.data = torch.from_numpy(w2 * self.r2 / self.r1.transpose())\n",
    "            self.fc3.weight.data = torch.from_numpy(w3 / self.r2.transpose())\n",
    "            self.fc3.weight.data.add_(self.r3)\n",
    "        self.y2 = None\n",
    "        self.y3 = None\n",
    "        self.alpha = None\n",
    "    def forward(self, x):\n",
    "        y1 = self.fc1(x)\n",
    "        self.y2 = self.fc2(y1)\n",
    "        self.alpha = self.y2.sum()\n",
    "        self.y3 = self.fc3(self.y2)\n",
    "        self.y3.retain_grad()\n",
    "        return self.y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------- plaintext weight ---------------\ntensor([[0.2000, 0.3000],\n        [0.4000, 0.2000],\n        [0.3000, 0.4000]])\ntensor([[0.2000, 0.3000, 0.4000],\n        [0.4000, 0.2000, 0.3000],\n        [0.3000, 0.4000, 0.2000]])\ntensor([[0.2000, 0.3000, 0.4000],\n        [0.4000, 0.2000, 0.3000]])\ny:  tensor([[0.1206, 0.1221]], grad_fn=<MmBackward>)\n----------- plaintext grad -----------------\ntensor([[-0.0401, -0.0602],\n        [-0.0424, -0.0636],\n        [-0.0401, -0.0602]])\ntensor([[-0.0295, -0.0318, -0.0409],\n        [-0.0246, -0.0265, -0.0341],\n        [-0.0345, -0.0371, -0.0477]])\ntensor([[-0.0531, -0.0508, -0.0497],\n        [-0.0529, -0.0506, -0.0495]])\n----------- ciphertext weight ---------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "add_(): argument 'other' (position 1) must be Tensor, not numpy.ndarray",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-33e2485bb93b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mw_gradlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----------- ciphertext weight ---------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mnet_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCMlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencrypt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5daab1645568>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encrypt)\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw3\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add_(): argument 'other' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# setup gpu or cpu\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "r = (0.2, 0.4, 0.8)\n",
    "x = torch.tensor([[0.2, 0.3]], device=device)\n",
    "y_hat = torch.tensor([[0.5, 0.5]], device=device)\n",
    "\n",
    "net = CMlp().to(device)\n",
    "print('----------- plaintext weight ---------------')\n",
    "for p in net.parameters():\n",
    "    print(p.data)\n",
    "y = net(x)\n",
    "print('y: ', y)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(y, y_hat)\n",
    "loss.backward(retain_graph=True)\n",
    "print('----------- plaintext grad -----------------')\n",
    "for p in net.parameters():\n",
    "    print(p.grad)\n",
    "w_gradlist = [p.grad for p in net.parameters()]\n",
    "print('----------- ciphertext weight ---------------')\n",
    "net_c = CMlp(encrypt=True).to(device)\n",
    "for p in net_c.parameters():\n",
    "    print(p.data)\n",
    "y_c = net_c(x)\n",
    "c_loss = criterion(y_c, y_hat)\n",
    "c_loss.backward(retain_graph=True)\n",
    "print('----------- ciphertext grad ---------------')\n",
    "for p in net_c.parameters():\n",
    "    print(p.grad)\n",
    "c_w_gradlist = [p.grad for p in net_c.parameters()]\n",
    "\n",
    "print('Get yc: ', y_c)\n",
    "print('Get yc from y: ', y + net_c.alpha * 0.8)\n",
    "print('Ly derivative')\n",
    "print(y - y_hat)\n",
    "print(y.grad)\n",
    "print('Lhaty derivative')\n",
    "print(y_c - y_hat)\n",
    "print(y_c.grad)\n",
    "y_c_grad = y_c.grad"
   ]
  },
  {
   "source": [
    "$ \\frac{\\partial \\widehat{L}}{\\partial \\widehat{W}^{(l)}}  $"
   ],
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Optimizer(net.parameters(), {})\n",
    "optim_c = torch.optim.Optimizer(net_c.parameters(), {})"
   ]
  },
  {
   "source": [
    "### set grad to zero"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2755, -0.4132],\n",
      "        [-0.2829, -0.4244],\n",
      "        [-0.2754, -0.4131]], device='cuda:0')\n",
      "tensor([[-0.0201, -0.0216, -0.0278],\n",
      "        [-0.0185, -0.0199, -0.0256],\n",
      "        [-0.0217, -0.0234, -0.0300]], device='cuda:0')\n",
      "tensor([[-0.0140, -0.0134, -0.0131],\n",
      "        [-0.0139, -0.0133, -0.0130]], device='cuda:0')\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for p in net_c.parameters():\n",
    "    print(p.grad)\n",
    "optim_c.zero_grad()\n",
    "for p in net_c.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "source": [
    "## get $\\frac{\\partial \\alpha}{\\partial \\widehat{w}^{(l)}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3600, 0.5400],\n",
      "        [0.3600, 0.5400],\n",
      "        [0.3600, 0.5400]], device='cuda:0')\n",
      "tensor([[0.0260, 0.0280, 0.0360],\n",
      "        [0.0260, 0.0280, 0.0360],\n",
      "        [0.0260, 0.0280, 0.0360]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "net_c.alpha.backward(retain_graph=True)\n",
    "alpha_gradlist = [p.grad.detach().clone() for p in net_c.parameters()]\n",
    "for p in net_c.parameters():\n",
    "    print(p.grad)"
   ]
  },
  {
   "source": [
    "### set grad to zero and get $\\mathbf{r}^t \\frac{\\partial \\widehat{y}^{L}}{\\partial \\widehat{w}^{(l)}}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "optim_c.zero_grad()\n",
    "r = torch.tensor([[0.8, 0.8]], device=device)\n",
    "for p in net_c.parameters():\n",
    "    print(p.grad)\n",
    "y_c.backward(r, retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_yw_gradlist = [p.grad for p in net_c.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0448, 0.0429, 0.0419],\n",
      "        [0.0448, 0.0429, 0.0419]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(c_w_gradlist[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0531, -0.0508, -0.0497],\n",
      "        [-0.0529, -0.0506, -0.0495]], device='cuda:0')\n",
      "tensor([[0.0448, 0.0429, 0.0419],\n",
      "        [0.0448, 0.0429, 0.0419]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(w_gradlist[2])\n",
    "print(c_yw_gradlist[2])"
   ]
  },
  {
   "source": [
    "Compute $\\frac{\\partial \\widehat{L}}{\\partial \\widehat{W}}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\widehat{L}}{\\partial \\widehat{W}} = \\frac{1}{R^{(l)}} \\circ \\frac{\\partial L}{\\partial W} + r^T \\cdot \\alpha \\frac{\\partial \\widehat{y}^{(L)}}{\\partial \\widehat{W}} + r^T \\cdot (\\frac{ \\partial \\widehat{L}}{\\partial \\widehat{y}^{(L)}})^{T} \\frac{\\partial \\alpha}{\\partial \\widehat{W}} - r^T r \\alpha \\frac{\\partial \\alpha}{\\partial \\widehat{W}}\n",
    "\\end{equation}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Layer3 c_w3 grad with simple computing\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\widehat{L}}{\\partial \\widehat{W}} = \\frac{1}{R^{(l)}} \\circ \\frac{\\partial L}{\\partial W} + r^T \\cdot \\alpha \\frac{\\partial \\widehat{y}^{(L)}}{\\partial \\widehat{W}}\n",
    "\\end{equation}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0140, -0.0134, -0.0131],\n",
      "        [-0.0139, -0.0133, -0.0130]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(w_gradlist[2] * 0.4 + c_yw_gradlist[2] * net_c.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2498, -0.2483]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_c_grad.reshape(1, -1))\n",
    "t = r.matmul(y_c_grad.reshape(1, -1).t())"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0295, -0.0318, -0.0409],\n",
      "        [-0.0246, -0.0265, -0.0341],\n",
      "        [-0.0345, -0.0371, -0.0477]], device='cuda:0')\n",
      "tensor([[0.0260, 0.0280, 0.0360],\n",
      "        [0.0260, 0.0280, 0.0360],\n",
      "        [0.0260, 0.0280, 0.0360]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(w_gradlist[1])\n",
    "print(alpha_gradlist[1])"
   ]
  },
  {
   "source": [
    "## Layer2 c_w2 grad"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0201, -0.0216, -0.0278],\n",
      "        [-0.0185, -0.0199, -0.0256],\n",
      "        [-0.0217, -0.0234, -0.0300]], device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(w_gradlist[1] * 0.5 + c_yw_gradlist[1] * net_c.alpha + alpha_gradlist[1] * t - r.matmul(r.t()) * net_c.alpha * alpha_gradlist[1])"
   ]
  },
  {
   "source": [
    "## Layer1 c_w1 grad"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2755, -0.4132],\n",
      "        [-0.2829, -0.4244],\n",
      "        [-0.2754, -0.4131]], device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(w_gradlist[0] * 5 + c_yw_gradlist[0] * net_c.alpha + alpha_gradlist[0] * t - r.matmul(r.t()) * net_c.alpha * alpha_gradlist[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python375jvsc74a57bd01e47ec2281ab428d4ca22f0f74965e4cc9a389189477cc90a3919c72a06fb43f",
   "display_name": "Python 3.7.5 64-bit ('torch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}